---
permalink: /
title: "Yao Wu (吴垚)"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

🌈 I am a Ph.D. student at the School of Informatics, at Xiamen University, China, supervised by Professor Yanyun Qu (曲延云教授). I received the M.S. degree in Department of Mechanical Engineering from Taiwan University, China, in 2019, supervised by Professor Han-Pang Huang (黄漢邦教授).

🏳️‍🌈 My research interests include, but are not limited to: Computer Vision (3D computer vision, image and point cloud semantic segmentation), Machine Learning (weakly-supervised learning, semi-supervised learning, unsupervised learning, transfer learning). Recently, I have focused on **3D domain adaptation and 3D domain generalization**. If you are interested in my research or have any use cases that you want to share, feel free to contact me! (📧: wuyao@stu.xmu.edu.cn)

_______________________________________________________________________________________________________
<h3>
  <a name="news"></a> ✍News
</h3>
<div class="mini">
  <ul>
  <li> <strong>[Jul 2025]</strong> 🎉One paper about multi-modal testing-time adaptation is accepted by <strong>ACMMM 2025</strong>!</li>
  <li> <strong>[May 2025]</strong> 🎉One paper about unsupervised anomaly localization is accepted by <strong>TNNLS (IF: 10.4)</strong>!</li>
  <li> <strong>[Mar 2025]</strong> 🎉One paper about multi-modal unsupervised domain adaptation is accepted by <strong>ICME 2025</strong>!</li>
  <li> <strong>[Feb 2025]</strong> 🎉One paper about multi-modal unsupervised domain adaptation is accepted by <strong>TCSVT (IF: 8.3)</strong>!</li>
  <li> <strong>[Dec 2024]</strong> 🎉One paper about active source-free domain adaptation is accepted by <strong>AAAI 2025</strong>!</li>
  <li> <strong>[Oct 2024]</strong> 🎉One paper about generalized zero-shot learning is accepted by <strong>TCSVT (IF: 8.3)</strong>!</li>
  <li> <strong>[Sep 2024]</strong> 🎉One paper about unified cross-domain 3D semantic segmentation is accepted by <strong>NeurIPS 2024</strong>!</li>
  <li> <strong>[Jul 2024]</strong> 🎉One paper about multi-modal unsupervised domain adaptation is accepted by <strong>ACMMM 2024</strong>!</li>
  <li> <strong>[Apr 2024]</strong> 🎉One paper about few-shot anomaly classification is accepted by <strong>IJCAI 2024</strong>!</li>
  <li> <strong>[Oct 2023]</strong> 🎉One paper about semi-supervised defect segmentation is accepted by <strong>TNNLS (IF: 10.4)</strong>!</li>
  <li> <strong>[Jul 2023]</strong> 🎉One paper about multi-modal unsupervised domain adaptation is accepted by <strong>ACMMM 2023</strong>!</li>
  </ul>
</div>

<style>
table, th, td {
  border: none;
  border-collapse: collapse;
}
</style>

_______________________________________________________________________________________________________

<h3>
  <a name="Publications"></a> 📚Selected Publications (1️⃣ Equal contribution, 📧 Corresponding author)
</h3>

<font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="0" cellpadding="0" class="noBorder">
           <tbody>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="300" src="../images/PLATO-TTA.png" border="0">
                    </td>
                    <td>
                      <b>PLATO-TTA: Prototype-Guided Pseudo-Labeling and Adaptive Tuning for Multi-Modal Test-Time Adaptation of 3D Segmentation </b>
                      <br>
                      Jianxiang Xie, <strong>Yao Wu</strong>1️⃣, Yachao Zhang, Xiaopei Zhang, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>ACM International Conference on Multimedia (ACMMM 2025) </em>
                      <br>
                      [<a href="">Paper</a>][<a href="">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="300" src="../images/FtDPlus.png" border="0">
                    </td>
                    <td>
                      <b>Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation </b>
                      <br>
                      <strong>Yao Wu</strong>, Mingwei Xing, Yachao Zhang, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2025) </em>
                      <br>
                      [<a href="https://ieeexplore.ieee.org/document/10904908">Paper</a>][<a href="https://github.com/Barcaaaa/FtD-PlusPlus">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="300" src="../images/ActiveSFDA.png" border="0">
                    </td>
                    <td>
                      <b>Omni-Query Active Learning for Source-Free Domain Adaptive Cross-Modality 3D Semantic Segmentation </b>
                      <br>
                      Jianxiang Xie, <strong>Yao Wu</strong>1️⃣, Yachao Zhang, Zhongchao Shi, Jianping Fan, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>Association for the Advancement of Artificial Intelligence (AAAI 2025) </em>
                      <br>
                      [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32941">Paper</a>][<a href="https://github.com/Kylin-XJX/ActiveSFDA">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="300" src="../images/UniDSeg.jpg" border="0">
                    </td>
                    <td>
                      <b>UniDSeg: Unified Cross-Domain 3D Semantic Segmentation via Visual Foundation Models Prior </b>
                      <br>
                      <strong>Yao Wu</strong>, Mingwei Xing, Yachao Zhang, Xiaotong Luo, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>Annual Conference on Neural Information Processing Systems (NeurIPS 2024) </em>
                      <br>
                      [<a href="https://neurips.cc/virtual/2024/poster/94354">Paper</a>][<a href="https://github.com/Barcaaaa/UniDSeg">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="350" src="../images/RE-GZSL.jpg" border="0">
                    </td>
                    <td>
                      <b>RE-GZSL: Relation Extrapolation for Generalized Zero-Shot Learning </b>
                      <br>
                      <strong>Yao Wu</strong>, Xia Kong, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2024) </em>
                      <br>
                      [<a href="https://ieeexplore.ieee.org/document/10734386">Paper</a>][<a href="https://github.com/Barcaaaa/RE-GZSL">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="400" src="../images/CLIP2UDA.png" border="0">
                    </td>
                    <td>
                      <b>CLIP2UDA: Making Frozen CLIP Reward Unsupervised Domain Adaptation in 3D Semantic Segmentation </b>
                      <br>
                      <strong>Yao Wu</strong>, Mingwei Xing, Yachao Zhang, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>ACM International Conference on Multimedia (ACMMM 2024) </em>
                      <br>
                      [<a href="https://openreview.net/forum?id=Ai1ziPxtmr&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Dacmmm.org%2FACMMM%2F2024%2FConference%2FAuthors%23your-submissions)">Paper</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                      <div style="text-align: center;">
                        <img width="300" src="../images/CLIP-FSAC.png" border="0">
                      </div>
                    </td>
                    <td>
                      <b>CLIP-FSAC: Boosting CLIP for Few-Shot Anomaly Classification with Synthetic Anomalies </b>
                      <br>
                      Zuo Zuo, <strong>Yao Wu</strong>1️⃣, Baoqiang Li, Jiahao Dong, You Zhou, Lei Zhou, Yanyun Qu, Zongze Wu. 
                      <br>
                      <em>International Joint Conference on Artificial Intelligence (IJCAI 2024) </em>
                      <br>
                      [<a href="https://www.ijcai.org/proceedings/2024/0203.pdf">Paper</a>][<a href="https://github.com/Jay-zzcoder/clip-fsac-pp">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="240" src="../images/PPL.png" border="0">
                    </td>
                    <td>
                      <b>Perturbed Progressive Learning for Semisupervised Defect Segmentation </b>
                      <br>
                      <strong>Yao Wu</strong>, Mingwei Xing, Yachao Zhang, Yuan Xie, Zongze Wu, Yanyun Qu. 
                      <br>
                      <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS 2023) </em>
                      <br>
                      [<a href="https://doi.org/10.1109/TNNLS.2023.3324188">Paper</a>][<a href="https://github.com/Barcaaaa/Perturbed-Progressive-Learning">Code</a>]
                    </td>
            </tr>
            <tr>
                    <td class="noBorder" width="40%" align="center">
                        <img width="400" src="../images/BFtD.png" border="0">
                    </td>
                    <td>
                      <b>Cross-modal Unsupervised Domain Adaptation for 3D Semantic Segmentation via Bidirectional Fusion-then-Distillation </b>
                      <br>
                      <strong>Yao Wu</strong>, Mingwei Xing, Yachao Zhang, Jianping Fan, Zhongchao Shi, Yuan Xie, Yanyun Qu. 
                      <br>
                      <em>ACM International Conference on Multimedia (ACMMM 2023) </em>
                      <br>
                      [<a href="https://dl.acm.org/doi/10.1145/3581783.3612013">Paper</a>][<a href="https://github.com/Barcaaaa/BFtD-xMUDA">Code</a>]
                    </td>
             </tr>
          </tbody>
      </table>
</font>


[Please visit [my google scholar profile](https://scholar.google.com.hk/citations?user=QYbmS-YAAAAJ&hl=zh-CN) for the full publication list and [my github homepage](https://github.com/Barcaaaa) for recent works.]

_______________________________________________________________________________________________________

<h3>
  <a name="services"></a> 📠Academic Services
</h3>
<div class="mini">
  <ul>
  <li> <strong>Conference Reviewer</strong>: NeurIPS, ICCV, AAAI, ACMMM, ICME, ‌MMAsia </li>
  <li> <strong>Journal Reviewer</strong>: IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </li>
  </ul>
</div>

_______________________________________________________________________________________________________

<h3>
  <a name="services"></a> ✨Hobby
</h3>
<div class="mini">
 <td width="30%">
 <img width="60" src="../images/football.jpg" border="0">
</td>
   <td width="30%">
 <img width="60" src="../images/game.jpg" border="0">
</td>
   <td width="30%">
 <img width="60" src="../images/music.jpg" border="0">
</td>
   <td width="30%">
 <img width="60" src="../images/travel.jpg" border="0">
</td>
</div>

